{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_names = [\"Status of existing checking account\", \"Duration in months\", \"Credit history\", \"Purpose\", \"Credit amount\",\n",
    "           \"Savings account/bonds\", \"Present employment since\", \"Installment rate in percentage of disposable income\",\n",
    "           \"Personal status and sex\", \"Other debtors / guarantors\", \"Present residence since\", \"Property\", \"Age in years\",\n",
    "           \"Other installment plans\", \"Housing\", \"Number of existing credits at this bank\", \"Job\", \n",
    "           \"Number of people being liable to provide maintenance for\", \"Telephone\", \"Foreign worker\", \"Good flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"german.data\", sep=\" \", names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data.corr(\"spearman\")[\"Good flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data['Good flag'] = raw_data[\"Good flag\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in raw_data.columns:\n",
    "    if column != \"Credit amount\":\n",
    "        print(raw_data.groupby(by=column)[\"Good flag\"].sum()/raw_data.groupby(by=column)[\"Good flag\"].count(), raw_data.groupby(by=column)[\"Good flag\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data[\"Duration in months\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data[\"Duration in months binned\"] = pd.cut(raw_data[\"Duration in months\"], bins=[0, 6, 12, 15, 18, 24, 30, 36, 72])\n",
    "raw_data[\"Age in years binned\"] = pd.cut(raw_data[\"Age in years\"], bins=[19, 25, 30, 35, 40, 50, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_vars = list(raw_data.dtypes.where(raw_data.dtypes == 'int64').dropna().index)\n",
    "numeric_vars.remove('Good flag')\n",
    "cat_vars = list(raw_data.dtypes.where(raw_data.dtypes != 'int64').dropna().index)\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "raw_data_scaled = pd.DataFrame(scale(raw_data[numeric_vars]), columns=numeric_vars)\n",
    "dummy_attr = pd.get_dummies(raw_data[cat_vars], dummy_na=True)\n",
    "dummy_data = raw_data_scaled.merge(dummy_attr, left_index=True, right_index=True)\n",
    "dummy_data['Good flag'] = raw_data['Good flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "train_data, oos_data = train_test_split(dummy_data, test_size=0.2, random_state=0, stratify=dummy_data[\"Good flag\"])\n",
    "\n",
    "attr = list(train_data.columns.copy())\n",
    "attr.remove(\"Good flag\")\n",
    "\n",
    "X = train_data[attr].values\n",
    "y = train_data[\"Good flag\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Scikit-Learn's classes API consist of three main functions - \n",
    "<code>fit()</code> - fitting a given class to data;\n",
    "<code>transform()</code> - transforms the data in a certain way;\n",
    "<code>predict()</code> - gives the output of a model or algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree - basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_clf.fit(X, y)\n",
    "roc_auc_score(tree_clf.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From the above the tree is clearly overfitting. Let's investigate the structure of the tree\n",
    "tree_clf.tree_.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "def graph_tree(clf, attr_list):\n",
    "    dot_data = export_graphviz(clf, out_file=None, feature_names=attr_list, filled=True, rounded=True,\n",
    "                           special_characters=True)  \n",
    "    graph = graphviz.Source(dot_data)  \n",
    "    return graph\n",
    "\n",
    "graph_tree(tree_clf, attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees - regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <code>max_depth</code> - specifies how many \"levels\" a decision tree can have;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_clf2 = DecisionTreeClassifier(max_depth=2, class_weight='balanced')\n",
    "tree_clf2.fit(X, y)\n",
    "print(roc_auc_score(tree_clf2.predict(X), y))\n",
    "\n",
    "graph_tree(tree_clf2, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Example of Gini-impurity at middle node\n",
    "node_value = tree_clf2.tree_.value \n",
    "sum_vals = node_value[1].sum()\n",
    "gini = node_value[1][0][0]/sum_vals * (1-node_value[1][0][0]/sum_vals) + node_value[1][0][1]/sum_vals * (1-node_value[1][0][1]/sum_vals)\n",
    "print(gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_importances(clf):\n",
    "    features = pd.DataFrame([clf.feature_importances_], columns=attr).transpose()\n",
    "    return features.sort_values(by=0, ascending=False).head(n=5)\n",
    "\n",
    "feature_importances(tree_clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <code>min_samples_split</code> - the minimum number of samples required to split a node (can be given asa fraction);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_clf2 = DecisionTreeClassifier(min_samples_split=80, class_weight='balanced')\n",
    "tree_clf2.fit(X, y)\n",
    "print(roc_auc_score(tree_clf2.predict(X), y))\n",
    "\n",
    "graph_tree(tree_clf2, attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <code>min_samples_leaf</code> - the minimum number of samples required to be at a leaf node (can be given as a fraction);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_clf2 = DecisionTreeClassifier(min_samples_leaf=80, class_weight='balanced')\n",
    "#tree_clf2 = DecisionTreeClassifier(min_samples_leaf=0.1)\n",
    "tree_clf2.fit(X, y)\n",
    "print(roc_auc_score(tree_clf2.predict(X), y))\n",
    "\n",
    "graph_tree(tree_clf2, attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <code>min_weight_fraction_leaf</code> - the minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_clf2 = DecisionTreeClassifier(min_weight_fraction_leaf=0.1)\n",
    "tree_clf2.fit(X, y)\n",
    "print(roc_auc_score(tree_clf2.predict(X), y))\n",
    "\n",
    "graph_tree(tree_clf2, attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <code>max_features</code> - the number of features to consider when looking for the best split;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_clf2 = DecisionTreeClassifier(max_features=50, class_weight='balanced')\n",
    "tree_clf2.fit(X, y)\n",
    "print(roc_auc_score(tree_clf2.predict(X), y))\n",
    "\n",
    "graph_tree(tree_clf2, attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <code>max_leaf_nodes</code> - grow a tree with <code>max_leaf_nodes</code> in best-first fashion;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_clf2 = DecisionTreeClassifier(max_leaf_nodes=4, class_weight='balanced')\n",
    "tree_clf2.fit(X, y)\n",
    "print(roc_auc_score(tree_clf2.predict(X), y))\n",
    "\n",
    "graph_tree(tree_clf2, attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <code>min_impurity_decrease</code> - a node will be split if this split induces a decrease of the impurity greater than or equal to this value;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_clf2 = DecisionTreeClassifier(min_impurity_decrease=0.01, class_weight='balanced')\n",
    "tree_clf2.fit(X, y)\n",
    "print(roc_auc_score(tree_clf2.predict(X), y))\n",
    "\n",
    "graph_tree(tree_clf2, attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <code>class_weight</code> - weights associated with classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests - basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise</b>\n",
    "\n",
    "Using <code>RandomForestClassifier</code> class train a random forest and compute ROC AUC score. Use two of the regulariztion parameters for decision tree to train your model - a random forest is basically a lot of decision trees. Try also changing the number of trees of your forest using <code>n_estimators</code> parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking which features were the most important for the forest trained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_importances(frst_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting - basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise</b>\n",
    "\n",
    "Using <code>GradientBoostingClassifier</code> class train a gradient boosting classifier and compute ROC AUC score. Afterwards, check which features were the most important using <code>feature\\_importances\\_</code> attribute. You can control learning rate with <code>learning\\_rate</code> parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks - basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn_clf = MLPClassifier()\n",
    "nn_clf.fit(X, y)\n",
    "roc_auc_score(nn_clf.predict(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <code>hidden_layer_sizes</code> - a tuple with indices indicating number of neurons in hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise</b>\n",
    "\n",
    "Using <code>MLPClassifier</code> class train a neural network with 600 neurons in the first hidden layer. Compute ROC AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Basic parameters\n",
    "nn_clf.n_layers_, nn_clf.n_outputs_, nn_clf.out_activation_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <code>activation</code> - activation function from a list \\[‘identity’, ‘logistic’, ‘tanh’, ‘relu’\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise</b>\n",
    "\n",
    "Using the code from the cell above train a neural network with one of the activation functions above (defualt is 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <code>learning_rate</code> - defines the learning rate update schedule as per one of the schedules from the list {‘constant’, ‘invscaling’, ‘adaptive’} - 'constant' means no change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Source: https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curves ('tanh' activation function)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=20, test_size=0.2, random_state=0)\n",
    "\n",
    "plot_learning_curve(nn_clf, title, X, y, ylim=(0.6, 1), cv=cv, n_jobs=-1)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_clf1 = MLPClassifier(hidden_layer_sizes=(600,), activation='logistic')\n",
    "nn_clf.fit(X, y)\n",
    "#roc_auc_score(nn_clf.predict(X), y)\n",
    "\n",
    "title = \"Learning Curves ('logistic' activation function)\"\n",
    "\n",
    "plot_learning_curve(nn_clf1, title, X, y, ylim=(0.65, 1.05), cv=cv, n_jobs=-1)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_clf1 = MLPClassifier(hidden_layer_sizes=(600,), activation='logistic', learning_rate='invscaling')\n",
    "nn_clf.fit(X, y)\n",
    "#roc_auc_score(nn_clf.predict(X), y)\n",
    "\n",
    "title = \"Learning Curves ('logistic' activation function)\"\n",
    "\n",
    "plot_learning_curve(nn_clf1, title, X, y, ylim=(0.65, 1.05), cv=cv, n_jobs=-1)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <code>max_iter</code> - terminate learning after specified amount of iterations;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise</b>\n",
    "\n",
    "Train a neural network with <code>max_iter</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise</b>\n",
    "\n",
    "Using <code>SVC</code> class train supporting vector machine and compute ROC AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-sample validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise</b>\n",
    "\n",
    "Using <code>test_train_split</code> function split the <code>train_data</code> set into <code>train_in_sample</code> and <code>train_out_of_sample</code> sets, split them into <code>X_is, X_oos, y_is, y_os</code> with 80-20 proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise</b>\n",
    "\n",
    "Choose a classifying algorithm and train in on the in-sample set produced above. Using <code>predict()</code> method compute ROC AUC score on the in-sample and out-of-sample sets.\n",
    "\n",
    "Compare your results with other colleagues who used the same algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    tree_clf2.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"The in-sample ROC AUC score for the \", index, \"split is \", \n",
    "          roc_auc_score(tree_clf2.predict(X_train), y_train), \".\")\n",
    "    print(\"The out-of-sample ROC AUC score for the \", index, \"split is \", \n",
    "          roc_auc_score(tree_clf2.predict(X_test), y_test), \".\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise</b>\n",
    "\n",
    "Validate any of the algorithms discussed above and decide whether it's better than the decision tree trained above using average ROC AUC score from the out-of-sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid_tree = [\n",
    "    {'splitter': ['best', 'random'], 'max_depth': [2, 4, 6, 8]},\n",
    "    {'splitter': ['best', 'random'], 'min_samples_split': [2, 6, 10, 16]},\n",
    "    {'splitter': ['best', 'random'], 'min_samples_leaf': [1, 2, 4]},\n",
    "    {'splitter': ['best', 'random'], 'max_features': [10, \"auto\", \"sqrt\", None]},\n",
    "    {'splitter': ['best', 'random'], 'max_leaf_nodes': [50, 100, 150]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grd_tree = GridSearchCV(DecisionTreeClassifier(class_weight='balanced'), param_grid_tree,\n",
    "                        cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grd_tree.fit(X, y)\n",
    "grd_tree.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_tree(grd_tree.best_estimator_,attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise</b>\n",
    "\n",
    "Try out some combinations of regularization parameters. Check which parameters were chosen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercise</b>\n",
    "\n",
    "Eperiment with <code>RandomForestClassifier</code> and <code>GradientBoostingClassifier</code>. Check what best results you can get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class DataSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attr_names):\n",
    "        self.attr_names = attr_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attr_names].values\n",
    "    \n",
    "class DataDummy(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        dummy = pd.get_dummies(pd.DataFrame(X), dummy_na=True)\n",
    "        return dummy.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('select_attr', DataSelector(numeric_vars)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('select_attr', DataSelector(cat_vars)),\n",
    "    ('scaler', DataDummy())\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipe', num_pipeline),\n",
    "    ('cat_pipe', cat_pipeline)\n",
    "])\n",
    "\n",
    "data_prepared = full_pipeline.fit_transform(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
